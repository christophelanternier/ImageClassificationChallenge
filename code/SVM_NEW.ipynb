{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from classification import *\n",
    "from numpy import genfromtxt\n",
    "import pywt\n",
    "from kernel import *\n",
    "from datetime import time, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr = genfromtxt('../data/Xtr.csv', delimiter=',')\n",
    "Ytr = genfromtxt('../data/Ytr.csv', delimiter=',')\n",
    "Xte = genfromtxt('../data/Xte.csv', delimiter=',')\n",
    "\n",
    "Xtr = np.delete(Xtr, 3072, axis=1)\n",
    "Xte = np.delete(Xte, 3072, axis=1)\n",
    "Ytr = Ytr[1:,1]\n",
    "N = len(Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_transform(Xtr):\n",
    "    result = np.zeros((Xtr.shape[0], 972))\n",
    "\n",
    "    for i in range(Xtr.shape[0]):\n",
    "        r = Xtr[i][:1024].reshape(32,32)\n",
    "        g = Xtr[i][1024:2048].reshape(32,32)\n",
    "        b = Xtr[i][-1024:].reshape(32,32)\n",
    "\n",
    "        rgbArray = np.zeros((32,32,3), 'uint8')\n",
    "        rgbArray[..., 0] = (r+r.min())/(r.max()-r.min())*256\n",
    "        rgbArray[..., 1] = (g+g.min())/(g.max()-g.min())*256\n",
    "        rgbArray[..., 2] = (b+b.min())/(b.max()-b.min())*256\n",
    "\n",
    "        grayImage = 0.2989 *rgbArray[..., 0]+ 0.5870 *rgbArray[..., 1]+0.1140 *rgbArray[..., 2]\n",
    "        coeffs2 = pywt.dwt2(grayImage, 'bior1.3')\n",
    "        LL, (LH, HL, HH) = coeffs2\n",
    "\n",
    "        result[i,:] = np.concatenate((LH.ravel(), HL.ravel(), HH.ravel()), axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_versus_all_SVM(features, labels, _lambda):\n",
    "    N = len(labels)\n",
    "    n_labels = len(set(labels))\n",
    "    alphas = np.zeros((n_labels, N))\n",
    "    bias = np.zeros(n_labels)\n",
    "    \n",
    "    #Linear Kernel:\n",
    "    K = features.T.dot(features)\n",
    "    \n",
    "    for label in range(n_labels):\n",
    "        one_versus_all_labels = np.zeros(N)\n",
    "        for i in range(N):\n",
    "            if labels[i] == label:\n",
    "                one_versus_all_labels[i] = 1\n",
    "            else:\n",
    "                one_versus_all_labels[i] = -1\n",
    "        alphas[label, :], bias[label] = train_SVM(K, one_versus_all_labels, _lambda)\n",
    "        print \"classifier for label \", label, \" done\"\n",
    "        \n",
    "    return alphas, bias\n",
    "\n",
    "def predict_SVM(alphas, bias, features, X):    \n",
    "    y_pred = np.zeros(alphas.shape[0])\n",
    "    values_pred = np.zeros((alphas.shape[0],X.shape[1]))\n",
    "    for k in range(alphas.shape[0]):\n",
    "        values_pred[k,:] = alphas[k,:].dot(features.T.dot(X))+bias[k]\n",
    "    return np.argmax(values_pred, axis=0)\n",
    "\n",
    "def train_SVM(K, y, _lambda):\n",
    "    \n",
    "    n = y.shape[0]\n",
    "    gamma = 1 / (2 * _lambda * n)\n",
    "    \n",
    "    P = cvxopt.matrix(K)\n",
    "    \n",
    "    h = cvxopt.matrix(0., (2 * n, 1))\n",
    "    h[:n] = gamma\n",
    "    \n",
    "    A = cvxopt.matrix(1., (1, n))\n",
    "    b = cvxopt.matrix(0.)\n",
    "    \n",
    "    y = y.astype(np.double)\n",
    "    diag_y = cvxopt.spdiag(y.tolist())\n",
    "    q = cvxopt.matrix(-y)\n",
    "    G = cvxopt.sparse([diag_y, -diag_y])    \n",
    "\n",
    "    res = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    \n",
    "    return np.array(res[\"x\"]).T, res[\"y\"][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test new SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr_t = fourier_modulus_2D_kernel(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr_train = Xtr_t[:4000, :].T\n",
    "Xtr_test = Xtr_t[4000:, :].T\n",
    "Ytr_train = Ytr[:4000]\n",
    "Ytr_test = Ytr[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = Xtr_train\n",
    "labels = Ytr_train\n",
    "X = Xtr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.2241e+02 -1.1445e+01  3e+04  2e+02  5e-11\n",
      " 1: -8.2988e+00 -1.1343e+01  5e+02  3e+00  5e-11\n",
      " 2: -1.5322e+00 -1.0160e+01  4e+01  2e-01  3e-12\n",
      " 3: -9.5904e-01 -5.6220e+00  7e+00  2e-02  4e-13\n",
      " 4: -8.6546e-01 -2.1499e+00  2e+00  4e-03  1e-13\n",
      " 5: -8.9988e-01 -1.3425e+00  5e-01  9e-04  8e-14\n",
      " 6: -9.3449e-01 -1.1001e+00  2e-01  2e-04  8e-14\n",
      " 7: -9.5699e-01 -1.0077e+00  5e-02  3e-06  9e-14\n",
      " 8: -9.6705e-01 -9.8321e-01  2e-02  6e-09  1e-13\n",
      " 9: -9.7062e-01 -9.7573e-01  5e-03  5e-17  1e-13\n",
      "10: -9.7218e-01 -9.7308e-01  9e-04  1e-17  9e-14\n",
      "11: -9.7251e-01 -9.7257e-01  6e-05  3e-17  9e-14\n",
      "12: -9.7253e-01 -9.7253e-01  2e-06  2e-17  9e-14\n",
      "13: -9.7253e-01 -9.7253e-01  4e-08  5e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  0  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.5701e+02 -1.1491e+01  3e+04  2e+02  4e-11\n",
      " 1: -6.9179e+00 -1.1386e+01  5e+02  3e+00  5e-11\n",
      " 2: -1.4415e+00 -1.0135e+01  4e+01  2e-01  3e-12\n",
      " 3: -9.1409e-01 -5.6715e+00  8e+00  2e-02  5e-13\n",
      " 4: -8.0286e-01 -2.4172e+00  2e+00  6e-03  1e-13\n",
      " 5: -8.1572e-01 -1.2972e+00  6e-01  1e-03  1e-13\n",
      " 6: -8.5702e-01 -1.0617e+00  2e-01  4e-04  1e-13\n",
      " 7: -8.8406e-01 -9.6179e-01  8e-02  9e-05  1e-13\n",
      " 8: -8.9854e-01 -9.2010e-01  2e-02  5e-06  1e-13\n",
      " 9: -9.0486e-01 -9.0853e-01  4e-03  3e-08  1e-13\n",
      "10: -9.0629e-01 -9.0652e-01  2e-04  1e-09  1e-13\n",
      "11: -9.0638e-01 -9.0639e-01  6e-06  3e-11  1e-13\n",
      "12: -9.0638e-01 -9.0638e-01  2e-07  8e-13  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  1  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0988e+02 -1.1065e+01  3e+04  2e+02  5e-11\n",
      " 1: -7.8430e+00 -1.0959e+01  4e+02  3e+00  5e-11\n",
      " 2: -1.5072e+00 -9.7389e+00  3e+01  2e-01  3e-12\n",
      " 3: -9.2396e-01 -5.4014e+00  7e+00  2e-02  4e-13\n",
      " 4: -8.2692e-01 -2.0434e+00  1e+00  3e-03  1e-13\n",
      " 5: -8.6574e-01 -1.2287e+00  4e-01  6e-04  1e-13\n",
      " 6: -8.9557e-01 -1.0565e+00  2e-01  9e-05  1e-13\n",
      " 7: -9.1581e-01 -9.7589e-01  6e-02  2e-05  1e-13\n",
      " 8: -9.2509e-01 -9.4888e-01  2e-02  2e-17  1e-13\n",
      " 9: -9.3052e-01 -9.3643e-01  6e-03  1e-17  1e-13\n",
      "10: -9.3218e-01 -9.3320e-01  1e-03  8e-17  1e-13\n",
      "11: -9.3255e-01 -9.3262e-01  7e-05  8e-17  1e-13\n",
      "12: -9.3258e-01 -9.3258e-01  2e-06  1e-16  1e-13\n",
      "13: -9.3258e-01 -9.3258e-01  5e-08  1e-16  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  2  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.1538e+02 -1.1281e+01  3e+04  2e+02  4e-11\n",
      " 1: -8.1165e+00 -1.1164e+01  5e+02  3e+00  4e-11\n",
      " 2: -1.6580e+00 -9.9050e+00  4e+01  2e-01  3e-12\n",
      " 3: -9.6638e-01 -5.6771e+00  7e+00  2e-02  3e-13\n",
      " 4: -8.7471e-01 -2.0009e+00  1e+00  3e-03  1e-13\n",
      " 5: -9.0518e-01 -1.3461e+00  5e-01  9e-04  9e-14\n",
      " 6: -9.3265e-01 -1.0854e+00  2e-01  1e-04  1e-13\n",
      " 7: -9.4855e-01 -1.0132e+00  6e-02  4e-06  1e-13\n",
      " 8: -9.5835e-01 -9.8158e-01  2e-02  1e-06  1e-13\n",
      " 9: -9.6289e-01 -9.6962e-01  7e-03  1e-17  1e-13\n",
      "10: -9.6470e-01 -9.6599e-01  1e-03  2e-17  1e-13\n",
      "11: -9.6512e-01 -9.6526e-01  1e-04  2e-17  1e-13\n",
      "12: -9.6517e-01 -9.6518e-01  8e-06  5e-17  1e-13\n",
      "13: -9.6518e-01 -9.6518e-01  3e-07  4e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  3  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0873e+02 -1.1052e+01  3e+04  2e+02  5e-11\n",
      " 1: -7.6131e+00 -1.0964e+01  4e+02  3e+00  5e-11\n",
      " 2: -1.4836e+00 -9.7931e+00  3e+01  1e-01  3e-12\n",
      " 3: -9.3225e-01 -5.3264e+00  7e+00  2e-02  4e-13\n",
      " 4: -8.4312e-01 -2.1039e+00  2e+00  4e-03  1e-13\n",
      " 5: -8.7346e-01 -1.2643e+00  4e-01  8e-04  7e-14\n",
      " 6: -9.0649e-01 -1.0505e+00  1e-01  2e-04  7e-14\n",
      " 7: -9.2450e-01 -9.8263e-01  6e-02  2e-05  7e-14\n",
      " 8: -9.3294e-01 -9.5761e-01  2e-02  7e-17  8e-14\n",
      " 9: -9.3880e-01 -9.4467e-01  6e-03  3e-17  7e-14\n",
      "10: -9.4035e-01 -9.4178e-01  1e-03  3e-17  7e-14\n",
      "11: -9.4080e-01 -9.4097e-01  2e-04  2e-17  8e-14\n",
      "12: -9.4086e-01 -9.4087e-01  1e-05  1e-17  8e-14\n",
      "13: -9.4087e-01 -9.4087e-01  3e-07  1e-17  8e-14\n",
      "Optimal solution found.\n",
      "classifier for label  4  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.6466e+02 -1.0915e+01  3e+04  2e+02  6e-11\n",
      " 1: -7.0439e+00 -1.0819e+01  4e+02  3e+00  5e-11\n",
      " 2: -1.4843e+00 -9.6655e+00  4e+01  2e-01  4e-12\n",
      " 3: -8.8643e-01 -5.7155e+00  8e+00  2e-02  5e-13\n",
      " 4: -7.7946e-01 -2.3607e+00  2e+00  6e-03  2e-13\n",
      " 5: -7.9437e-01 -1.2244e+00  5e-01  9e-04  1e-13\n",
      " 6: -8.2696e-01 -1.0443e+00  2e-01  3e-04  1e-13\n",
      " 7: -8.4361e-01 -9.6885e-01  1e-01  1e-04  1e-13\n",
      " 8: -8.5408e-01 -9.2243e-01  7e-02  2e-17  1e-13\n",
      " 9: -8.6795e-01 -8.8945e-01  2e-02  6e-17  1e-13\n",
      "10: -8.7340e-01 -8.7860e-01  5e-03  3e-17  1e-13\n",
      "11: -8.7510e-01 -8.7564e-01  5e-04  2e-17  1e-13\n",
      "12: -8.7531e-01 -8.7533e-01  2e-05  2e-17  1e-13\n",
      "13: -8.7532e-01 -8.7532e-01  7e-07  1e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  5  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.3112e+02 -1.1079e+01  3e+04  2e+02  5e-11\n",
      " 1: -6.1278e+00 -1.0996e+01  5e+02  3e+00  5e-11\n",
      " 2: -1.2388e+00 -9.8493e+00  3e+01  1e-01  3e-12\n",
      " 3: -7.9967e-01 -5.3028e+00  7e+00  2e-02  4e-13\n",
      " 4: -6.7515e-01 -2.0003e+00  2e+00  4e-03  1e-13\n",
      " 5: -7.0005e-01 -1.1007e+00  5e-01  1e-03  1e-13\n",
      " 6: -7.4023e-01 -8.7989e-01  1e-01  2e-04  1e-13\n",
      " 7: -7.6631e-01 -8.0279e-01  4e-02  6e-06  1e-13\n",
      " 8: -7.7579e-01 -7.8496e-01  9e-03  1e-17  1e-13\n",
      " 9: -7.7915e-01 -7.8002e-01  9e-04  2e-17  1e-13\n",
      "10: -7.7949e-01 -7.7955e-01  6e-05  5e-17  1e-13\n",
      "11: -7.7951e-01 -7.7952e-01  2e-06  4e-17  1e-13\n",
      "12: -7.7951e-01 -7.7951e-01  3e-08  1e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  6  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7279e+02 -1.1239e+01  3e+04  2e+02  6e-11\n",
      " 1: -6.9147e+00 -1.1157e+01  5e+02  3e+00  6e-11\n",
      " 2: -1.3658e+00 -1.0039e+01  3e+01  2e-01  4e-12\n",
      " 3: -8.6874e-01 -5.2810e+00  7e+00  2e-02  5e-13\n",
      " 4: -7.7848e-01 -1.8352e+00  1e+00  3e-03  1e-13\n",
      " 5: -8.1848e-01 -1.2074e+00  4e-01  8e-04  1e-13\n",
      " 6: -8.4708e-01 -1.0353e+00  2e-01  3e-04  1e-13\n",
      " 7: -8.6496e-01 -9.5756e-01  9e-02  8e-05  1e-13\n",
      " 8: -8.7551e-01 -9.2018e-01  5e-02  2e-05  1e-13\n",
      " 9: -8.8343e-01 -8.9850e-01  2e-02  2e-17  1e-13\n",
      "10: -8.8721e-01 -8.9164e-01  4e-03  2e-17  1e-13\n",
      "11: -8.8837e-01 -8.8954e-01  1e-03  4e-17  1e-13\n",
      "12: -8.8881e-01 -8.8891e-01  1e-04  1e-17  1e-13\n",
      "13: -8.8885e-01 -8.8885e-01  3e-06  1e-17  1e-13\n",
      "14: -8.8885e-01 -8.8885e-01  7e-08  7e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  7  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8837e+02 -1.1172e+01  3e+04  2e+02  4e-11\n",
      " 1: -7.3011e+00 -1.1079e+01  5e+02  3e+00  4e-11\n",
      " 2: -1.3691e+00 -9.9151e+00  3e+01  1e-01  3e-12\n",
      " 3: -8.9861e-01 -5.3300e+00  7e+00  2e-02  4e-13\n",
      " 4: -7.9178e-01 -2.2209e+00  2e+00  5e-03  1e-13\n",
      " 5: -8.0416e-01 -1.2301e+00  5e-01  1e-03  9e-14\n",
      " 6: -8.3832e-01 -1.0250e+00  2e-01  4e-04  9e-14\n",
      " 7: -8.4939e-01 -9.7304e-01  1e-01  2e-04  9e-14\n",
      " 8: -8.5987e-01 -9.3527e-01  8e-02  6e-05  9e-14\n",
      " 9: -8.6348e-01 -9.1537e-01  5e-02  1e-16  1e-13\n",
      "10: -8.7298e-01 -8.9917e-01  3e-02  1e-16  9e-14\n",
      "11: -8.7980e-01 -8.8767e-01  8e-03  2e-17  1e-13\n",
      "12: -8.8227e-01 -8.8374e-01  1e-03  2e-17  1e-13\n",
      "13: -8.8287e-01 -8.8296e-01  1e-04  1e-16  1e-13\n",
      "14: -8.8291e-01 -8.8291e-01  3e-06  2e-16  1e-13\n",
      "15: -8.8291e-01 -8.8291e-01  4e-08  8e-17  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  8  done\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.2685e+02 -1.0524e+01  3e+04  2e+02  4e-11\n",
      " 1: -6.5367e+00 -1.0453e+01  4e+02  3e+00  4e-11\n",
      " 2: -1.3017e+00 -9.4356e+00  4e+01  2e-01  3e-12\n",
      " 3: -8.1703e-01 -5.1991e+00  7e+00  2e-02  4e-13\n",
      " 4: -6.9754e-01 -2.0872e+00  2e+00  5e-03  1e-13\n",
      " 5: -6.9792e-01 -1.0947e+00  5e-01  1e-03  9e-14\n",
      " 6: -7.3805e-01 -8.6068e-01  1e-01  1e-04  1e-13\n",
      " 7: -7.6005e-01 -8.0262e-01  4e-02  2e-05  1e-13\n",
      " 8: -7.6982e-01 -7.8139e-01  1e-02  2e-06  1e-13\n",
      " 9: -7.7366e-01 -7.7502e-01  1e-03  2e-07  1e-13\n",
      "10: -7.7419e-01 -7.7425e-01  7e-05  7e-09  1e-13\n",
      "11: -7.7421e-01 -7.7422e-01  2e-06  2e-10  1e-13\n",
      "12: -7.7421e-01 -7.7421e-01  6e-08  5e-12  1e-13\n",
      "Optimal solution found.\n",
      "classifier for label  9  done\n",
      "model fitted\n",
      "0:00:36.289902\n"
     ]
    }
   ],
   "source": [
    "t1 = datetime.now()\n",
    "alphas, bias = one_versus_all_SVM(features, labels, _lambda=0.1)\n",
    "print 'model fitted'\n",
    "prediction = predict_SVM(alphas, bias, features, X)\n",
    "t2 = datetime.now()\n",
    "print t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32\n"
     ]
    }
   ],
   "source": [
    "well_classified = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == Ytr_test[i]:\n",
    "         well_classified+=1\n",
    "print float(well_classified)/len(Ytr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 150\n",
    "mean_1 = [0, -3]\n",
    "cov = [[3, 0], [0, 3]]\n",
    "X_1 = np.random.multivariate_normal(mean_1, cov, n_samples).T\n",
    "mean_2 = [3, 3]\n",
    "X_2 = np.random.multivariate_normal(mean_2, cov, n_samples).T\n",
    "mean_3 = [-3, 3]\n",
    "X_3 = np.random.multivariate_normal(mean_3, cov, n_samples).T\n",
    "X = np.concatenate((X_1, X_2, X_3), axis = 1)\n",
    "\n",
    "y = np.concatenate((np.zeros((1,n_samples)), np.ones((1, n_samples)), 2*np.ones((1,n_samples))), axis=1)\n",
    "y = y[0,:]\n",
    "Xtr_t = X.T\n",
    "Ytr = y\n",
    "\n",
    "mask_test = range(0,450, 5)\n",
    "mask_train = [i for i in range(450) if i not in mask_test]\n",
    "\n",
    "Xtr_train = Xtr_t[mask_train, :].T\n",
    "Xtr_test = Xtr_t[mask_test, :].T\n",
    "Ytr_train = Ytr[mask_train]\n",
    "Ytr_test = Ytr[mask_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
